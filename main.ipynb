{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmQebzEwMJB0AACKXwijgm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf_tXDe25qmG",
        "outputId": "f5388a14-f08e-4c29-c4da-b0788e71b850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8011 - loss: 15.2733 - val_accuracy: 0.4321 - val_loss: 30.6027\n",
            "Epoch 2/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.9519 - loss: 0.9543 - val_accuracy: 0.5479 - val_loss: 8.2805\n",
            "Epoch 3/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1s/step - accuracy: 0.9412 - loss: 2.3163 - val_accuracy: 0.7082 - val_loss: 12.7131\n",
            "Epoch 4/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9522 - loss: 1.2883 - val_accuracy: 0.9243 - val_loss: 1.3533\n",
            "Epoch 5/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9383 - loss: 6.7190 - val_accuracy: 0.8820 - val_loss: 3.4173\n",
            "Epoch 6/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.9825 - loss: 0.2005 - val_accuracy: 0.8886 - val_loss: 1.5648\n",
            "Epoch 7/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 1s/step - accuracy: 0.9778 - loss: 0.2214 - val_accuracy: 0.8196 - val_loss: 18.5208\n",
            "Epoch 8/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.9600 - loss: 1.6281 - val_accuracy: 0.6904 - val_loss: 103.4097\n",
            "Epoch 9/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.9622 - loss: 1.7824 - val_accuracy: 0.8597 - val_loss: 7.5161\n",
            "Epoch 10/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 1s/step - accuracy: 0.9764 - loss: 0.4095 - val_accuracy: 0.8708 - val_loss: 3.2509\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 192ms/step\n",
            "Mean Average Precision (mAP): 0.8953229398663697\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, LeakyReLU, BatchNormalization, Dense, Flatten, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "\n",
        "# Load Dataset from Train, Valid, and Test folders\n",
        "def load_dataset(base_path):\n",
        "    def load_images_and_labels(json_path, image_dir):\n",
        "      with open(json_path, 'r') as f:\n",
        "          data = json.load(f)\n",
        "\n",
        "      images, labels = [], []\n",
        "      for item in data['images']:\n",
        "          img_path = os.path.join(image_dir, item['file_name'])\n",
        "          img = cv2.imread(img_path)\n",
        "          if img is None:\n",
        "              continue\n",
        "          img = cv2.resize(img, (64, 64)) / 127.5 - 1  # Normalize\n",
        "          images.append(img)\n",
        "\n",
        "          # Find the corresponding annotation for this image using the image id\n",
        "          image_id = item['id']\n",
        "          annotation = next((ann for ann in data['annotations'] if ann['image_id'] == image_id), None)\n",
        "\n",
        "          if annotation:\n",
        "              labels.append(annotation['category_id'] - 1)\n",
        "          else:\n",
        "              # case where image has no annotation.\n",
        "              images.pop()\n",
        "\n",
        "      return np.array(images), np.array(labels)\n",
        "\n",
        "    train_images, train_labels = load_images_and_labels(os.path.join(base_path, 'train', '_annotations.coco.json'), os.path.join(base_path, 'train')) # Replace with the actual file name\n",
        "    val_images, val_labels = load_images_and_labels(os.path.join(base_path, 'valid', '_annotations.coco.json'), os.path.join(base_path, 'valid')) # Replace with the actual file name\n",
        "    test_images, test_labels = load_images_and_labels(os.path.join(base_path, 'test', '_annotations.coco.json'), os.path.join(base_path, 'test')) # Replace with the actual file name\n",
        "\n",
        "    return train_images, val_images, test_images, train_labels, val_labels, test_labels\n",
        "\n",
        "# Custom Small Object Detection Model\n",
        "def build_custom_model():\n",
        "    inputs = tf.keras.Input(shape=(64, 64, 3))\n",
        "    x = Conv2D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(3, activation='softmax')(x)  # Multi-class classification for Vehicles, Ships, Aircraft\n",
        "\n",
        "    return Model(inputs, x, name='SmallObjectDetector')\n",
        "\n",
        "# Training and Evaluation\n",
        "def train_and_evaluate(model, X_train, y_train, X_val, y_val, X_test, y_test, epochs=10, batch_size=16):\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    # Evaluate Model\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    mAP = np.mean(y_pred == y_test)  #mAP calculation\n",
        "    print(f\"Mean Average Precision (mAP): {mAP}\")\n",
        "\n",
        "# Load Data and Train Model\n",
        "base_path = '/content/SkyFusion'\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = load_dataset(base_path)\n",
        "model = build_custom_model()\n",
        "train_and_evaluate(model, X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "\n"
      ]
    }
  ]
}